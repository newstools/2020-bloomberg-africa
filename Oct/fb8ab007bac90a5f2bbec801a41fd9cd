Facebook Inc. Chief Executive Officer Mark Zuckerberg, like many Americans, expects election night to be confusing. He’s worried it could also be violent. “There is, unfortunately, I think, a heightened risk of civil unrest in the period between voting and a result being called,” Zuckerberg told Axios last month. “I think we need to be doing everything that we can to reduce the chances of violence or civil unrest in the wake of this election.” Social media companies are facing heightened scrutiny and pressure to do more to keep their platforms from becoming vectors of misinformation, election meddling and all-around disorder. Over the past two months, Facebook and rival network Twitter Inc. have rolled out new policies as they brace for a complicated and possibly chaotic election night, in which results may be unclear or delayed. Both companies updated their rules this week, a sign that they’re still fine-tuning their strategies less than a month before Election Day. Any delay in the official declaration of winners on the night of Nov. 3 is likely to cause confusion for voters -- and could provide an opportunity for people, including the candidates themselves, to spread incomplete or inaccurate information online. Some watchers worry that a lack of clear answers or conflicting information about voting outcomes could lead to riots or protests. Others have warned about possible intimidation at polling places, or that misinformation about how or when to vote could mean people don’t vote at all. Here are some of the things Facebook and Twitter are doing in preparation for election night: In many cases, misleading info posted on both services will be labeled, but not removed, leading some election watchers to question how effective this strategy will be. “It’s just as problematic” to leave misleading posts up even if they have a label, said Michael Serazio, as associate professor of communication at Boston College. “In 2020 there is a real fear and anxiety about what will circulate on social media in the absence of a declared winner.” Labels linking to additional information puts the onus on Facebook users to do the actual fact-checking, as the tags themselves don’t necessarily say outright that a post is wrong, said Gautam Hans, a First Amendment law professor at Vanderbilt Law School. “It’s just more information for people to parse through,” Hans said, “and people are notoriously bad at doing that.” Google-owned YouTube is dealing with similar issues. The video platform draws millions of viewers to its political and news videos, which have added traffic since the pandemic began. The company has taken several measures to suppress political misinformation on its site. Google itself plans to shut off political ads on its properties once polls close on Nov. 3. YouTube also bans doctored footage and videos that incite violence, mislead people about voting or “interfere with democratic processes.” However, the company declined to say how it would treat videos from a candidate or others that declare an outcome that doesn’t match official counts. “We continue to stay vigilant and are working to have the right protections in place leading up to, on and after election day, globally,” said Ivy Choi, a YouTube spokeswoman. One challenge for all the online services will be speed. Even if these companies do label posts from violating politicians, those messages can achieve massive reach in minutes. After Trump tweeted earlier this week suggesting that Covid-19 was no worse than the flu, Twitter hid the post behind a warning label -- but not before it garnered more than 180,000 likes and more than 43,000 retweets. Some of Twitter’s labels, like the one applied to Trump’s Covid tweet, block users from liking or sharing a tweet further. But by the time companies act to halt the spread of misinformation, much of the damage may already be done. Some lawmakers expressed worry that Facebook and Google’s advertising policies are short-sighted. “That political ads will be blocked on Facebook and Google after polls close on election day do little to stop bad actors from pushing dangerous disinformation organically,” wrote U.S. Representative Cheri Bustos of Illinois, the chairwoman of the Democratic Congressional Campaign Committee, and Senator Catherine Cortez Masto of Nevada, the chairwoman of the Democratic Senatorial Campaign Committee, in a statement. The two lawmakers continued to question whether technology companies were prepared for “potential run-off scenarios or urgent announcements like protocol around recounts.” “I think that it is good that the companies are aware of this,” Hans said. “November 3rd is going to be election night in some ways, but I just think this is going to play out a lot longer than that for obvious reasons, and I hope that the companies are ready for that saga.” — With assistance by Mark Bergen